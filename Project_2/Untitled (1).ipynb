{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(134435, 2381) (134435,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "filename = 'bodmas.npz'\n",
    "data = np.load(filename)\n",
    "X = data['X']  # all the feature vectors\n",
    "y = data['y']  # labels, 0 as benign, 1 as malicious\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05674198, 0.00801749, 0.00776239, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.00706228, 0.00449971, 0.00449817, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.0209748 , 0.00469876, 0.00400208, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.1423067 , 0.01637877, 0.01097404, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.14230758, 0.01637877, 0.01097404, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.1423067 , 0.01637877, 0.01097404, ..., 0.        , 0.        ,\n",
       "        0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2371</th>\n",
       "      <th>2372</th>\n",
       "      <th>2373</th>\n",
       "      <th>2374</th>\n",
       "      <th>2375</th>\n",
       "      <th>2376</th>\n",
       "      <th>2377</th>\n",
       "      <th>2378</th>\n",
       "      <th>2379</th>\n",
       "      <th>2380</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.056742</td>\n",
       "      <td>0.008017</td>\n",
       "      <td>0.007762</td>\n",
       "      <td>0.005466</td>\n",
       "      <td>0.007762</td>\n",
       "      <td>0.004446</td>\n",
       "      <td>0.005430</td>\n",
       "      <td>0.003061</td>\n",
       "      <td>0.009475</td>\n",
       "      <td>0.006305</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.007062</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>0.004498</td>\n",
       "      <td>0.004318</td>\n",
       "      <td>0.004410</td>\n",
       "      <td>0.004330</td>\n",
       "      <td>0.004265</td>\n",
       "      <td>0.004068</td>\n",
       "      <td>0.004391</td>\n",
       "      <td>0.004306</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>16564.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.020975</td>\n",
       "      <td>0.004699</td>\n",
       "      <td>0.004002</td>\n",
       "      <td>0.004419</td>\n",
       "      <td>0.004214</td>\n",
       "      <td>0.003865</td>\n",
       "      <td>0.003973</td>\n",
       "      <td>0.004297</td>\n",
       "      <td>0.003921</td>\n",
       "      <td>0.004145</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.006482</td>\n",
       "      <td>0.003821</td>\n",
       "      <td>0.003788</td>\n",
       "      <td>0.003866</td>\n",
       "      <td>0.003734</td>\n",
       "      <td>0.003784</td>\n",
       "      <td>0.003884</td>\n",
       "      <td>0.003937</td>\n",
       "      <td>0.003805</td>\n",
       "      <td>0.003809</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>16384.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.022135</td>\n",
       "      <td>0.003972</td>\n",
       "      <td>0.003834</td>\n",
       "      <td>0.003869</td>\n",
       "      <td>0.003759</td>\n",
       "      <td>0.003765</td>\n",
       "      <td>0.003777</td>\n",
       "      <td>0.003863</td>\n",
       "      <td>0.003773</td>\n",
       "      <td>0.003798</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2381 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3         4         5         6     \\\n",
       "0  0.056742  0.008017  0.007762  0.005466  0.007762  0.004446  0.005430   \n",
       "1  0.007062  0.004500  0.004498  0.004318  0.004410  0.004330  0.004265   \n",
       "2  0.020975  0.004699  0.004002  0.004419  0.004214  0.003865  0.003973   \n",
       "3  0.006482  0.003821  0.003788  0.003866  0.003734  0.003784  0.003884   \n",
       "4  0.022135  0.003972  0.003834  0.003869  0.003759  0.003765  0.003777   \n",
       "\n",
       "       7         8         9     ...  2371  2372  2373  2374   2375     2376  \\\n",
       "0  0.003061  0.009475  0.006305  ...   0.0   0.0   0.0   0.0    0.0      0.0   \n",
       "1  0.004068  0.004391  0.004306  ...   0.0   0.0   0.0   0.0  120.0  16564.0   \n",
       "2  0.004297  0.003921  0.004145  ...   0.0   0.0   0.0   0.0    0.0      0.0   \n",
       "3  0.003937  0.003805  0.003809  ...   0.0   0.0   0.0   0.0  140.0  16384.0   \n",
       "4  0.003863  0.003773  0.003798  ...   0.0   0.0   0.0   0.0    0.0      0.0   \n",
       "\n",
       "   2377  2378  2379  2380  \n",
       "0   0.0   0.0   0.0   0.0  \n",
       "1   0.0   0.0   0.0   0.0  \n",
       "2   0.0   0.0   0.0   0.0  \n",
       "3   0.0   0.0   0.0   0.0  \n",
       "4   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 2381 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data = pd.DataFrame(X)\n",
    "\n",
    "X_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.60842377, -0.12217378,  0.1805374 , ..., -0.01712796,\n",
       "        -0.08373784, -0.01359115],\n",
       "       [-0.8692141 , -0.32849306, -0.28640357, ..., -0.01712796,\n",
       "        -0.08373784, -0.01359115],\n",
       "       [-0.7961812 , -0.31681883, -0.35736898, ..., -0.01712796,\n",
       "        -0.08373784, -0.01359115],\n",
       "       ...,\n",
       "       [-0.15925756,  0.3682181 ,  0.6399592 , ..., -0.01712796,\n",
       "        -0.08373784, -0.01359115],\n",
       "       [-0.15925296,  0.3682181 ,  0.6399592 , ..., -0.01712796,\n",
       "        -0.08373784, -0.01359115],\n",
       "       [-0.15925756,  0.3682181 ,  0.6399592 , ..., -0.01712796,\n",
       "        -0.08373784, -0.01359115]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X_data)\n",
    "\n",
    "X_scaled = scaler.transform(X_data)\n",
    "\n",
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2371</th>\n",
       "      <th>2372</th>\n",
       "      <th>2373</th>\n",
       "      <th>2374</th>\n",
       "      <th>2375</th>\n",
       "      <th>2376</th>\n",
       "      <th>2377</th>\n",
       "      <th>2378</th>\n",
       "      <th>2379</th>\n",
       "      <th>2380</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.608424</td>\n",
       "      <td>-0.122174</td>\n",
       "      <td>0.180537</td>\n",
       "      <td>0.037640</td>\n",
       "      <td>0.104279</td>\n",
       "      <td>0.074880</td>\n",
       "      <td>0.095710</td>\n",
       "      <td>-0.105049</td>\n",
       "      <td>0.986098</td>\n",
       "      <td>0.953684</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018853</td>\n",
       "      <td>-0.022043</td>\n",
       "      <td>-0.01347</td>\n",
       "      <td>-0.016921</td>\n",
       "      <td>-0.013642</td>\n",
       "      <td>-0.023642</td>\n",
       "      <td>-0.012886</td>\n",
       "      <td>-0.017128</td>\n",
       "      <td>-0.083738</td>\n",
       "      <td>-0.013591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.869214</td>\n",
       "      <td>-0.328493</td>\n",
       "      <td>-0.286404</td>\n",
       "      <td>-0.149405</td>\n",
       "      <td>-0.299842</td>\n",
       "      <td>0.046777</td>\n",
       "      <td>-0.108178</td>\n",
       "      <td>0.159002</td>\n",
       "      <td>-0.301954</td>\n",
       "      <td>0.343431</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018853</td>\n",
       "      <td>-0.022043</td>\n",
       "      <td>-0.01347</td>\n",
       "      <td>-0.016921</td>\n",
       "      <td>-0.013640</td>\n",
       "      <td>-0.023253</td>\n",
       "      <td>-0.012886</td>\n",
       "      <td>-0.017128</td>\n",
       "      <td>-0.083738</td>\n",
       "      <td>-0.013591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.796181</td>\n",
       "      <td>-0.316819</td>\n",
       "      <td>-0.357369</td>\n",
       "      <td>-0.133002</td>\n",
       "      <td>-0.323490</td>\n",
       "      <td>-0.065683</td>\n",
       "      <td>-0.159356</td>\n",
       "      <td>0.219244</td>\n",
       "      <td>-0.420990</td>\n",
       "      <td>0.294160</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018853</td>\n",
       "      <td>-0.022043</td>\n",
       "      <td>-0.01347</td>\n",
       "      <td>-0.016921</td>\n",
       "      <td>-0.013642</td>\n",
       "      <td>-0.023642</td>\n",
       "      <td>-0.012886</td>\n",
       "      <td>-0.017128</td>\n",
       "      <td>-0.083738</td>\n",
       "      <td>-0.013591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.872262</td>\n",
       "      <td>-0.368316</td>\n",
       "      <td>-0.387939</td>\n",
       "      <td>-0.223022</td>\n",
       "      <td>-0.381233</td>\n",
       "      <td>-0.085246</td>\n",
       "      <td>-0.174898</td>\n",
       "      <td>0.124733</td>\n",
       "      <td>-0.450524</td>\n",
       "      <td>0.191508</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018853</td>\n",
       "      <td>-0.022043</td>\n",
       "      <td>-0.01347</td>\n",
       "      <td>-0.016921</td>\n",
       "      <td>-0.013640</td>\n",
       "      <td>-0.023257</td>\n",
       "      <td>-0.012886</td>\n",
       "      <td>-0.017128</td>\n",
       "      <td>-0.083738</td>\n",
       "      <td>-0.013591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.790089</td>\n",
       "      <td>-0.359461</td>\n",
       "      <td>-0.381473</td>\n",
       "      <td>-0.222588</td>\n",
       "      <td>-0.378263</td>\n",
       "      <td>-0.089918</td>\n",
       "      <td>-0.193634</td>\n",
       "      <td>0.105244</td>\n",
       "      <td>-0.458730</td>\n",
       "      <td>0.188095</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018853</td>\n",
       "      <td>-0.022043</td>\n",
       "      <td>-0.01347</td>\n",
       "      <td>-0.016921</td>\n",
       "      <td>-0.013642</td>\n",
       "      <td>-0.023642</td>\n",
       "      <td>-0.012886</td>\n",
       "      <td>-0.017128</td>\n",
       "      <td>-0.083738</td>\n",
       "      <td>-0.013591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2381 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3         4         5         6     \\\n",
       "0 -0.608424 -0.122174  0.180537  0.037640  0.104279  0.074880  0.095710   \n",
       "1 -0.869214 -0.328493 -0.286404 -0.149405 -0.299842  0.046777 -0.108178   \n",
       "2 -0.796181 -0.316819 -0.357369 -0.133002 -0.323490 -0.065683 -0.159356   \n",
       "3 -0.872262 -0.368316 -0.387939 -0.223022 -0.381233 -0.085246 -0.174898   \n",
       "4 -0.790089 -0.359461 -0.381473 -0.222588 -0.378263 -0.089918 -0.193634   \n",
       "\n",
       "       7         8         9     ...      2371      2372     2373      2374  \\\n",
       "0 -0.105049  0.986098  0.953684  ... -0.018853 -0.022043 -0.01347 -0.016921   \n",
       "1  0.159002 -0.301954  0.343431  ... -0.018853 -0.022043 -0.01347 -0.016921   \n",
       "2  0.219244 -0.420990  0.294160  ... -0.018853 -0.022043 -0.01347 -0.016921   \n",
       "3  0.124733 -0.450524  0.191508  ... -0.018853 -0.022043 -0.01347 -0.016921   \n",
       "4  0.105244 -0.458730  0.188095  ... -0.018853 -0.022043 -0.01347 -0.016921   \n",
       "\n",
       "       2375      2376      2377      2378      2379      2380  \n",
       "0 -0.013642 -0.023642 -0.012886 -0.017128 -0.083738 -0.013591  \n",
       "1 -0.013640 -0.023253 -0.012886 -0.017128 -0.083738 -0.013591  \n",
       "2 -0.013642 -0.023642 -0.012886 -0.017128 -0.083738 -0.013591  \n",
       "3 -0.013640 -0.023257 -0.012886 -0.017128 -0.083738 -0.013591  \n",
       "4 -0.013642 -0.023642 -0.012886 -0.017128 -0.083738 -0.013591  \n",
       "\n",
       "[5 rows x 2381 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled_data = pd.DataFrame(X_scaled)\n",
    "\n",
    "X_scaled_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(134435, 566)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import random_projection\n",
    "\n",
    "transformer = random_projection.SparseRandomProjection(eps = 0.5)\n",
    "\n",
    "X_new_data = transformer.fit_transform(X_scaled)\n",
    "\n",
    "X_new_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.18299921, -0.82088654, -0.72910802, ...,  0.0876474 ,\n",
       "         0.51230418,  1.29891056],\n",
       "       [-0.06866136, -0.32029337, -1.06678073, ..., -0.28809784,\n",
       "        -0.32051027,  1.77390096],\n",
       "       [ 1.71149791, -0.30056002,  0.21653413, ...,  2.15956795,\n",
       "        -1.04558462,  0.15236057],\n",
       "       ...,\n",
       "       [-3.65323859, -1.31224582,  0.70775958, ..., -0.69912214,\n",
       "         4.62709716,  0.93383087],\n",
       "       [-3.65323859, -1.31224582,  0.70775958, ..., -0.69912214,\n",
       "         4.62709716,  0.93382951],\n",
       "       [-3.65323859, -1.31224582,  0.70775958, ..., -0.69926433,\n",
       "         4.62709716,  0.93383087]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def fit_random_forest_classifier(X, y):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "    \n",
    "    clf = RandomForestClassifier(max_depth=None, random_state=42, n_estimators=100)\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_preds = clf.predict(X_test)\n",
    "    \n",
    "    #score\n",
    "    acc = accuracy_score(y_test, y_preds)\n",
    "    print(acc)\n",
    "    return acc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.994594728620664\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.994594728620664"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_random_forest_classifier(X_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.989164662418487\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.989164662418487"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_random_forest_classifier(X_new_data, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With epsilon = 0.30, the transformed data has 566 components. The random forest achieved an accuracz of:\n",
      "0.98923904688701\n",
      "--------------------------------\n",
      "With epsilon = 0.40, the transformed data has 566 components. The random forest achieved an accuracz of:\n",
      "0.9897597381666708\n",
      "--------------------------------\n",
      "With epsilon = 0.50, the transformed data has 566 components. The random forest achieved an accuracz of:\n",
      "0.9896605588753068\n",
      "--------------------------------\n",
      "With epsilon = 0.60, the transformed data has 566 components. The random forest achieved an accuracz of:\n",
      "0.9893878158240559\n",
      "--------------------------------\n",
      "With epsilon = 0.70, the transformed data has 566 components. The random forest achieved an accuracz of:\n",
      "0.9893878158240559\n",
      "--------------------------------\n",
      "With epsilon = 0.80, the transformed data has 566 components. The random forest achieved an accuracz of:\n",
      "0.9886439711388262\n",
      "--------------------------------\n",
      "With epsilon = 0.90, the transformed data has 566 components. The random forest achieved an accuracz of:\n",
      "0.9882472539733703\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "#loop to write a tranformation X using different epsilon\n",
    "\n",
    "for sample_eps in np.arange(0.3, 1, 0.1):\n",
    "    transformer = random_projection.SparseRandomProjection(eps = 0.5)\n",
    "    X_new_d = transformer.fit_transform(X_scaled)\n",
    "    \n",
    "    print(f\"With epsilon = {sample_eps:.2f}, the transformed data has {X_new_d.shape[1]} components. The random forest achieved an accuracz of:\")\n",
    "    fit_random_forest_classifier(X_new_d, y)\n",
    "    print(\"--------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(134435, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "X_new_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "X_new_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9152512955294935\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9152512955294935"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_random_forest_classifier(X_new_pca, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_pca(n_components, data):\n",
    "    pca = PCA(n_components)\n",
    "    X_data_pca = pca.fit_transform(data)\n",
    "    return pca, X_data_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comp 2\n",
      "0.913986759564603\n",
      "-----------------------------------\n",
      "comp 3\n",
      "0.9593612853636161\n",
      "-----------------------------------\n",
      "comp 4\n",
      "0.9724281570008182\n",
      "-----------------------------------\n",
      "comp 5\n",
      "0.9771143785177655\n",
      "-----------------------------------\n",
      "comp 6\n",
      "0.9816022414519848\n",
      "-----------------------------------\n",
      "comp 7\n",
      "0.9842800823188118\n",
      "-----------------------------------\n",
      "comp 8\n",
      "0.9851231062954056\n",
      "-----------------------------------\n",
      "comp 9\n",
      "0.9860405147405222\n",
      "-----------------------------------\n",
      "comp 10\n",
      "0.986809154248593\n",
      "-----------------------------------\n",
      "comp 11\n",
      "0.9873298455282536\n",
      "-----------------------------------\n",
      "comp 12\n",
      "0.9877017678708686\n",
      "-----------------------------------\n",
      "comp 13\n",
      "0.9875282041109816\n",
      "-----------------------------------\n",
      "comp 14\n",
      "0.9879745109221194\n",
      "-----------------------------------\n",
      "comp 15\n",
      "0.9886935607845082\n",
      "-----------------------------------\n",
      "comp 16\n",
      "0.9883216384418934\n",
      "-----------------------------------\n",
      "comp 17\n",
      "0.989040688304282\n",
      "-----------------------------------\n",
      "comp 18\n",
      "0.9888919193672361\n",
      "-----------------------------------\n",
      "comp 19\n",
      "0.989015893481441\n",
      "-----------------------------------\n",
      "comp 20\n",
      "0.9896853536981478\n",
      "-----------------------------------\n",
      "comp 21\n",
      "0.9897597381666708\n",
      "-----------------------------------\n",
      "comp 22\n",
      "0.9894126106468969\n",
      "-----------------------------------\n",
      "comp 23\n",
      "0.9894126106468969\n",
      "-----------------------------------\n",
      "comp 24\n",
      "0.9897845329895117\n",
      "-----------------------------------\n",
      "comp 25\n",
      "0.9901316605092857\n",
      "-----------------------------------\n",
      "comp 26\n",
      "0.9904787880290595\n",
      "-----------------------------------\n",
      "comp 27\n",
      "0.9899828915722397\n",
      "-----------------------------------\n",
      "comp 28\n",
      "0.9899828915722397\n",
      "-----------------------------------\n",
      "comp 29\n",
      "0.9895613795839429\n",
      "-----------------------------------\n",
      "comp 30\n",
      "0.9902308398006496\n",
      "-----------------------------------\n",
      "comp 31\n",
      "0.9904291983833775\n",
      "-----------------------------------\n",
      "comp 32\n",
      "0.9904787880290595\n",
      "-----------------------------------\n",
      "comp 33\n",
      "0.9902804294463317\n",
      "-----------------------------------\n",
      "comp 34\n",
      "0.9904787880290595\n",
      "-----------------------------------\n",
      "comp 35\n",
      "0.9901564553321267\n",
      "-----------------------------------\n",
      "comp 36\n",
      "0.9905283776747416\n",
      "-----------------------------------\n",
      "comp 37\n",
      "0.9903796087376956\n",
      "-----------------------------------\n",
      "comp 38\n",
      "0.9907515310803104\n",
      "-----------------------------------\n",
      "comp 39\n",
      "0.9907267362574694\n",
      "-----------------------------------\n",
      "comp 40\n",
      "0.9906771466117874\n",
      "-----------------------------------\n",
      "comp 41\n",
      "0.9910242741315614\n",
      "-----------------------------------\n",
      "comp 42\n",
      "0.9905283776747416\n",
      "-----------------------------------\n",
      "comp 43\n",
      "0.9910738637772433\n",
      "-----------------------------------\n",
      "comp 44\n",
      "0.9910738637772433\n",
      "-----------------------------------\n",
      "comp 45\n",
      "0.9906523517889465\n",
      "-----------------------------------\n",
      "comp 46\n",
      "0.9909746844858793\n",
      "-----------------------------------\n",
      "comp 47\n",
      "0.9904291983833775\n",
      "-----------------------------------\n",
      "comp 48\n",
      "0.9908507103716744\n",
      "-----------------------------------\n",
      "comp 49\n",
      "0.9906027621432645\n",
      "-----------------------------------\n",
      "comp 50\n",
      "0.9911730430686073\n",
      "-----------------------------------\n",
      "comp 51\n",
      "0.9909003000173564\n",
      "-----------------------------------\n",
      "comp 52\n",
      "0.9907019414346284\n",
      "-----------------------------------\n",
      "comp 53\n",
      "0.9909994793087203\n",
      "-----------------------------------\n",
      "comp 54\n",
      "0.9911482482457663\n",
      "-----------------------------------\n",
      "comp 55\n",
      "0.9909994793087203\n",
      "-----------------------------------\n",
      "comp 56\n",
      "0.9909003000173564\n",
      "-----------------------------------\n",
      "comp 57\n",
      "0.9913466068284942\n",
      "-----------------------------------\n",
      "comp 58\n",
      "0.9910738637772433\n",
      "-----------------------------------\n",
      "comp 59\n",
      "0.9908011207259925\n",
      "-----------------------------------\n",
      "comp 60\n",
      "0.9907019414346284\n",
      "-----------------------------------\n",
      "comp 61\n",
      "0.9910242741315614\n",
      "-----------------------------------\n",
      "comp 62\n",
      "0.9907019414346284\n",
      "-----------------------------------\n",
      "comp 63\n",
      "0.9908507103716744\n",
      "-----------------------------------\n",
      "comp 64\n",
      "0.9911978378914482\n",
      "-----------------------------------\n",
      "comp 65\n",
      "0.9912226327142892\n",
      "-----------------------------------\n",
      "comp 66\n",
      "0.9909250948401974\n",
      "-----------------------------------\n",
      "comp 67\n",
      "0.9912970171828123\n",
      "-----------------------------------\n",
      "comp 68\n",
      "0.9910738637772433\n",
      "-----------------------------------\n",
      "comp 69\n",
      "0.9912226327142892\n",
      "-----------------------------------\n",
      "comp 70\n",
      "0.9914209912970172\n",
      "-----------------------------------\n",
      "comp 71\n",
      "0.9911234534229253\n",
      "-----------------------------------\n",
      "comp 72\n",
      "0.9909498896630383\n",
      "-----------------------------------\n",
      "comp 73\n",
      "0.9913714016513352\n",
      "-----------------------------------\n",
      "comp 74\n",
      "0.9910986586000843\n",
      "-----------------------------------\n",
      "comp 75\n",
      "0.9912226327142892\n",
      "-----------------------------------\n",
      "comp 76\n",
      "0.9909003000173564\n",
      "-----------------------------------\n",
      "comp 77\n",
      "0.9908011207259925\n",
      "-----------------------------------\n",
      "comp 78\n",
      "0.9911234534229253\n",
      "-----------------------------------\n",
      "comp 79\n",
      "0.9910242741315614\n",
      "-----------------------------------\n",
      "comp 80\n",
      "0.9911234534229253\n",
      "-----------------------------------\n",
      "comp 81\n",
      "0.9911978378914482\n",
      "-----------------------------------\n",
      "comp 82\n",
      "0.9910738637772433\n",
      "-----------------------------------\n",
      "comp 83\n",
      "0.9909250948401974\n",
      "-----------------------------------\n",
      "comp 84\n",
      "0.9912970171828123\n",
      "-----------------------------------\n",
      "comp 85\n",
      "0.9910738637772433\n",
      "-----------------------------------\n",
      "comp 86\n",
      "0.9911482482457663\n",
      "-----------------------------------\n",
      "comp 87\n",
      "0.9912970171828123\n",
      "-----------------------------------\n",
      "comp 88\n",
      "0.9911482482457663\n",
      "-----------------------------------\n",
      "comp 89\n",
      "0.9911730430686073\n",
      "-----------------------------------\n",
      "comp 90\n",
      "0.9909003000173564\n",
      "-----------------------------------\n",
      "comp 91\n",
      "0.9913961964741762\n",
      "-----------------------------------\n",
      "comp 92\n",
      "0.9911482482457663\n",
      "-----------------------------------\n",
      "comp 93\n",
      "0.9912722223599713\n",
      "-----------------------------------\n",
      "comp 94\n",
      "0.9912226327142892\n",
      "-----------------------------------\n",
      "comp 95\n",
      "0.9910490689544024\n",
      "-----------------------------------\n",
      "comp 96\n",
      "0.9908507103716744\n",
      "-----------------------------------\n",
      "comp 97\n",
      "0.9911730430686073\n",
      "-----------------------------------\n",
      "comp 98\n",
      "0.9912474275371302\n",
      "-----------------------------------\n",
      "comp 99\n",
      "0.9909498896630383\n",
      "-----------------------------------\n",
      "comp 100\n",
      "0.9911730430686073\n",
      "-----------------------------------\n",
      "comp 101\n",
      "0.9911482482457663\n",
      "-----------------------------------\n",
      "comp 102\n",
      "0.9911978378914482\n",
      "-----------------------------------\n",
      "comp 103\n",
      "0.9910490689544024\n",
      "-----------------------------------\n",
      "comp 104\n",
      "0.9908011207259925\n",
      "-----------------------------------\n",
      "comp 105\n",
      "0.9909498896630383\n",
      "-----------------------------------\n",
      "comp 106\n",
      "0.9911482482457663\n",
      "-----------------------------------\n",
      "comp 107\n",
      "0.9911978378914482\n",
      "-----------------------------------\n",
      "comp 108\n",
      "0.9910738637772433\n",
      "-----------------------------------\n",
      "comp 109\n",
      "0.9909994793087203\n",
      "-----------------------------------\n",
      "comp 110\n",
      "0.9913714016513352\n",
      "-----------------------------------\n",
      "comp 111\n",
      "0.9909250948401974\n",
      "-----------------------------------\n",
      "comp 112\n",
      "0.9912474275371302\n",
      "-----------------------------------\n",
      "comp 113\n",
      "0.9909498896630383\n",
      "-----------------------------------\n",
      "comp 114\n",
      "0.9912226327142892\n",
      "-----------------------------------\n",
      "comp 115\n",
      "0.9910738637772433\n",
      "-----------------------------------\n",
      "comp 116\n",
      "0.9909003000173564\n",
      "-----------------------------------\n",
      "comp 117\n",
      "0.9912722223599713\n",
      "-----------------------------------\n",
      "comp 118\n",
      "0.9909746844858793\n",
      "-----------------------------------\n",
      "comp 119\n",
      "0.9912722223599713\n",
      "-----------------------------------\n",
      "comp 120\n",
      "0.9910738637772433\n",
      "-----------------------------------\n",
      "comp 121\n",
      "0.9913961964741762\n",
      "-----------------------------------\n",
      "comp 122\n",
      "0.9906275569661055\n",
      "-----------------------------------\n",
      "comp 123\n",
      "0.9905531724975825\n",
      "-----------------------------------\n",
      "comp 124\n",
      "0.9907763259031515\n",
      "-----------------------------------\n",
      "comp 125\n",
      "0.9912226327142892\n",
      "-----------------------------------\n",
      "comp 126\n",
      "0.9910490689544024\n",
      "-----------------------------------\n",
      "comp 127\n",
      "0.9910986586000843\n",
      "-----------------------------------\n",
      "comp 128\n",
      "0.9911730430686073\n",
      "-----------------------------------\n",
      "comp 129\n",
      "0.9908259155488334\n",
      "-----------------------------------\n",
      "comp 130\n",
      "0.9910986586000843\n",
      "-----------------------------------\n",
      "comp 131\n",
      "0.9908507103716744\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comp 132\n",
      "0.9909003000173564\n",
      "-----------------------------------\n",
      "comp 133\n",
      "0.9909250948401974\n",
      "-----------------------------------\n",
      "comp 134\n",
      "0.9913466068284942\n",
      "-----------------------------------\n",
      "comp 135\n",
      "0.9911234534229253\n",
      "-----------------------------------\n",
      "comp 136\n",
      "0.9909498896630383\n",
      "-----------------------------------\n",
      "comp 137\n",
      "0.9909994793087203\n",
      "-----------------------------------\n",
      "comp 138\n",
      "0.9907763259031515\n",
      "-----------------------------------\n",
      "comp 139\n",
      "0.9908259155488334\n",
      "-----------------------------------\n",
      "comp 140\n",
      "0.9908011207259925\n",
      "-----------------------------------\n",
      "comp 141\n",
      "0.9912226327142892\n",
      "-----------------------------------\n",
      "comp 142\n",
      "0.9907019414346284\n",
      "-----------------------------------\n",
      "comp 143\n",
      "0.9906771466117874\n",
      "-----------------------------------\n",
      "comp 144\n",
      "0.9910738637772433\n",
      "-----------------------------------\n",
      "comp 145\n",
      "0.9910490689544024\n",
      "-----------------------------------\n",
      "comp 146\n",
      "0.9910242741315614\n",
      "-----------------------------------\n",
      "comp 147\n",
      "0.9910986586000843\n",
      "-----------------------------------\n",
      "comp 148\n",
      "0.9910986586000843\n",
      "-----------------------------------\n",
      "comp 149\n",
      "0.9909994793087203\n",
      "-----------------------------------\n",
      "comp 150\n",
      "0.9907019414346284\n",
      "-----------------------------------\n",
      "comp 151\n",
      "0.9907763259031515\n",
      "-----------------------------------\n",
      "comp 152\n",
      "0.9908755051945154\n",
      "-----------------------------------\n",
      "comp 153\n",
      "0.9906771466117874\n",
      "-----------------------------------\n",
      "comp 154\n",
      "0.9907019414346284\n",
      "-----------------------------------\n",
      "comp 155\n",
      "0.9908755051945154\n",
      "-----------------------------------\n",
      "comp 156\n",
      "0.9909250948401974\n",
      "-----------------------------------\n",
      "comp 157\n",
      "0.9904787880290595\n",
      "-----------------------------------\n",
      "comp 158\n",
      "0.9911730430686073\n",
      "-----------------------------------\n",
      "comp 159\n",
      "0.9908755051945154\n",
      "-----------------------------------\n",
      "comp 160\n",
      "0.9910490689544024\n",
      "-----------------------------------\n",
      "comp 161\n",
      "0.9908507103716744\n",
      "-----------------------------------\n",
      "comp 162\n",
      "0.9908755051945154\n",
      "-----------------------------------\n",
      "comp 163\n",
      "0.9907267362574694\n",
      "-----------------------------------\n",
      "comp 164\n",
      "0.9909746844858793\n",
      "-----------------------------------\n",
      "comp 165\n",
      "0.9908011207259925\n",
      "-----------------------------------\n",
      "comp 166\n",
      "0.9909746844858793\n",
      "-----------------------------------\n",
      "comp 167\n",
      "0.9908755051945154\n",
      "-----------------------------------\n",
      "comp 168\n",
      "0.9910738637772433\n",
      "-----------------------------------\n",
      "comp 169\n",
      "0.9910986586000843\n",
      "-----------------------------------\n",
      "comp 170\n",
      "0.9909003000173564\n",
      "-----------------------------------\n",
      "comp 171\n",
      "0.9910242741315614\n",
      "-----------------------------------\n",
      "comp 172\n",
      "0.9909498896630383\n",
      "-----------------------------------\n",
      "comp 173\n",
      "0.9909003000173564\n",
      "-----------------------------------\n",
      "comp 174\n",
      "0.9907515310803104\n",
      "-----------------------------------\n",
      "comp 175\n",
      "0.9911234534229253\n",
      "-----------------------------------\n",
      "comp 176\n",
      "0.9908011207259925\n",
      "-----------------------------------\n",
      "comp 177\n",
      "0.9910242741315614\n",
      "-----------------------------------\n",
      "comp 178\n",
      "0.9908755051945154\n",
      "-----------------------------------\n",
      "comp 179\n",
      "0.9906771466117874\n",
      "-----------------------------------\n",
      "comp 180\n",
      "0.9911730430686073\n",
      "-----------------------------------\n",
      "comp 181\n",
      "0.9909003000173564\n",
      "-----------------------------------\n",
      "comp 182\n",
      "0.9904044035605366\n",
      "-----------------------------------\n",
      "comp 183\n",
      "0.9907763259031515\n",
      "-----------------------------------\n",
      "comp 184\n",
      "0.9909498896630383\n",
      "-----------------------------------\n",
      "comp 185\n",
      "0.9906523517889465\n",
      "-----------------------------------\n",
      "comp 186\n",
      "0.9907019414346284\n",
      "-----------------------------------\n",
      "comp 187\n",
      "0.9906027621432645\n",
      "-----------------------------------\n",
      "comp 188\n",
      "0.9905035828519005\n",
      "-----------------------------------\n",
      "comp 189\n",
      "0.9905035828519005\n",
      "-----------------------------------\n",
      "comp 190\n",
      "0.9911730430686073\n",
      "-----------------------------------\n",
      "comp 191\n",
      "0.9907267362574694\n",
      "-----------------------------------\n",
      "comp 192\n",
      "0.9907267362574694\n",
      "-----------------------------------\n",
      "comp 193\n",
      "0.9908011207259925\n",
      "-----------------------------------\n",
      "comp 194\n",
      "0.9909498896630383\n",
      "-----------------------------------\n",
      "comp 195\n",
      "0.9908011207259925\n",
      "-----------------------------------\n",
      "comp 196\n",
      "0.9906275569661055\n",
      "-----------------------------------\n",
      "comp 197\n",
      "0.9909498896630383\n",
      "-----------------------------------\n",
      "comp 198\n",
      "0.9908259155488334\n",
      "-----------------------------------\n",
      "comp 199\n",
      "0.9907019414346284\n",
      "-----------------------------------\n",
      "comp 200\n",
      "0.9905283776747416\n",
      "-----------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-0c4af7cc8404>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcomp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mpca\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_data_pca\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdo_pca\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_scaled\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"comp\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mfit_random_forest_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_data_pca\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"-----------------------------------\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-22508643b7e9>\u001b[0m in \u001b[0;36mdo_pca\u001b[1;34m(n_components, data)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdo_pca\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mpca\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mX_data_pca\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mpca\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_data_pca\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    367\u001b[0m         \u001b[0mC\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mordered\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse\u001b[0m \u001b[1;34m'np.ascontiguousarray'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m         \"\"\"\n\u001b[1;32m--> 369\u001b[1;33m         \u001b[0mU\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mV\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    370\u001b[0m         \u001b[0mU\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mU\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_components_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    416\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_full\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_svd_solver\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'arpack'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'randomized'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 418\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_truncated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_svd_solver\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    419\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    420\u001b[0m             raise ValueError(\"Unrecognized svd_solver='{0}'\"\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\u001b[0m in \u001b[0;36m_fit_truncated\u001b[1;34m(self, X, n_components, svd_solver)\u001b[0m\n\u001b[0;32m    533\u001b[0m                                      \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterated_power\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m                                      \u001b[0mflip_sign\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 535\u001b[1;33m                                      random_state=random_state)\n\u001b[0m\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_samples_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py\u001b[0m in \u001b[0;36mrandomized_svd\u001b[1;34m(M, n_components, n_oversamples, n_iter, power_iteration_normalizer, transpose, flip_sign, random_state)\u001b[0m\n\u001b[0;32m    346\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m     Q = randomized_range_finder(M, n_random, n_iter,\n\u001b[1;32m--> 348\u001b[1;33m                                 power_iteration_normalizer, random_state)\n\u001b[0m\u001b[0;32m    349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m     \u001b[1;31m# project M to the (k + p) dimensional space using the basis vectors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py\u001b[0m in \u001b[0;36mrandomized_range_finder\u001b[1;34m(A, size, n_iter, power_iteration_normalizer, random_state)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mQ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mQ\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mpower_iteration_normalizer\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'LU'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m             \u001b[0mQ\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msafe_sparse_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mQ\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpermute_l\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    233\u001b[0m             \u001b[0mQ\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msafe_sparse_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mQ\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpermute_l\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mpower_iteration_normalizer\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'QR'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    149\u001b[0m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m     if (sparse.issparse(a) and sparse.issparse(b)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for comp in range(2, 1000):\n",
    "    pca, X_data_pca = do_pca(comp, X_scaled)\n",
    "    print(\"comp\", comp)\n",
    "    fit_random_forest_classifier(X_data_pca, y)\n",
    "    print(\"-----------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(134435, 2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import FactorAnalysis\n",
    "\n",
    "transformer = FactorAnalysis(n_components=2, random_state=0)\n",
    "\n",
    "X_transformed = transformer.fit_transform(X_scaled)\n",
    "\n",
    "X_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9122263271428925\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9122263271428925"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_random_forest_classifier(X_transformed, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_FactorAnalysis(n_components, data):\n",
    "    FA = FactorAnalysis(n_components, random_state=42)\n",
    "    X_data_FA = FA .fit_transform(data)\n",
    "    return FA, X_data_FA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comp 50\n",
      "0.9906275569661055\n",
      "-----------------------------------\n",
      "comp 51\n",
      "0.9912226327142892\n",
      "-----------------------------------\n",
      "comp 52\n",
      "0.9910986586000843\n",
      "-----------------------------------\n",
      "comp 53\n",
      "0.9908755051945154\n",
      "-----------------------------------\n",
      "comp 54\n",
      "0.9906523517889465\n",
      "-----------------------------------\n",
      "comp 55\n",
      "0.9907515310803104\n",
      "-----------------------------------\n",
      "comp 56\n",
      "0.9909746844858793\n",
      "-----------------------------------\n",
      "comp 57\n",
      "0.9911730430686073\n",
      "-----------------------------------\n",
      "comp 58\n",
      "0.9909498896630383\n",
      "-----------------------------------\n",
      "comp 59\n",
      "0.9911978378914482\n",
      "-----------------------------------\n",
      "comp 60\n",
      "0.9908507103716744\n",
      "-----------------------------------\n",
      "comp 61\n",
      "0.9909250948401974\n",
      "-----------------------------------\n",
      "comp 62\n",
      "0.9911730430686073\n",
      "-----------------------------------\n",
      "comp 63\n",
      "0.9907515310803104\n",
      "-----------------------------------\n",
      "comp 64\n",
      "0.9906771466117874\n",
      "-----------------------------------\n",
      "comp 65\n",
      "0.9911730430686073\n",
      "-----------------------------------\n",
      "comp 66\n",
      "0.9906771466117874\n",
      "-----------------------------------\n",
      "comp 67\n",
      "0.9906027621432645\n",
      "-----------------------------------\n",
      "comp 68\n",
      "0.9907763259031515\n",
      "-----------------------------------\n",
      "comp 69\n",
      "0.9907515310803104\n",
      "-----------------------------------\n",
      "comp 70\n",
      "0.9907019414346284\n",
      "-----------------------------------\n",
      "comp 71\n",
      "0.9911978378914482\n",
      "-----------------------------------\n",
      "comp 72\n",
      "0.9907763259031515\n",
      "-----------------------------------\n",
      "comp 73\n",
      "0.9910490689544024\n",
      "-----------------------------------\n",
      "comp 74\n",
      "0.9908755051945154\n",
      "-----------------------------------\n",
      "comp 75\n",
      "0.9907267362574694\n",
      "-----------------------------------\n",
      "comp 76\n",
      "0.9907763259031515\n",
      "-----------------------------------\n",
      "comp 77\n",
      "0.9909498896630383\n",
      "-----------------------------------\n",
      "comp 78\n",
      "0.9904291983833775\n",
      "-----------------------------------\n",
      "comp 79\n",
      "0.9910242741315614\n",
      "-----------------------------------\n",
      "comp 80\n",
      "0.9905283776747416\n",
      "-----------------------------------\n",
      "comp 81\n",
      "0.9910242741315614\n",
      "-----------------------------------\n",
      "comp 82\n",
      "0.9911978378914482\n",
      "-----------------------------------\n",
      "comp 83\n",
      "0.9910242741315614\n",
      "-----------------------------------\n",
      "comp 84\n",
      "0.9910738637772433\n",
      "-----------------------------------\n",
      "comp 85\n",
      "0.9908507103716744\n",
      "-----------------------------------\n",
      "comp 86\n",
      "0.9912474275371302\n",
      "-----------------------------------\n",
      "comp 87\n",
      "0.9914953757655401\n",
      "-----------------------------------\n",
      "comp 88\n",
      "0.9912474275371302\n",
      "-----------------------------------\n",
      "comp 89\n",
      "0.9921400411594059\n",
      "-----------------------------------\n",
      "comp 90\n",
      "0.9913218120056532\n",
      "-----------------------------------\n",
      "comp 91\n",
      "0.9916193498797451\n",
      "-----------------------------------\n",
      "comp 92\n",
      "0.9910242741315614\n",
      "-----------------------------------\n",
      "comp 93\n",
      "0.9913466068284942\n",
      "-----------------------------------\n",
      "comp 94\n",
      "0.9917929136396321\n",
      "-----------------------------------\n",
      "comp 95\n",
      "0.9913714016513352\n",
      "-----------------------------------\n",
      "comp 96\n",
      "0.9917929136396321\n",
      "-----------------------------------\n",
      "comp 97\n",
      "0.9914953757655401\n",
      "-----------------------------------\n",
      "comp 98\n",
      "0.9919912722223599\n",
      "-----------------------------------\n",
      "comp 99\n",
      "0.9917929136396321\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "for comp in range(50, 100):\n",
    "    FA, X_data_FA = do_FactorAnalysis(comp, X_scaled)\n",
    "    print(\"comp\", comp)\n",
    "    fit_random_forest_classifier(X_data_FA, y)\n",
    "    print(\"-----------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
